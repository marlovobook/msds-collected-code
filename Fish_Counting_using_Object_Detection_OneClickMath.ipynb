{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPnqb8XRmzd4NVZ6M05yPO3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Connect Gdrive\n"],"metadata":{"id":"try7xbSmUo8N"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E6B9dV-wUPJm","executionInfo":{"status":"ok","timestamp":1762267706461,"user_tz":-420,"elapsed":17738,"user":{"displayName":"Piramid Surin","userId":"02095017345641733390"}},"outputId":"5d9376c2-5eea-49ac-8be0-fba9533d37be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## Install needed Libs"],"metadata":{"id":"Kyb59UM_UtvR"}},{"cell_type":"code","source":["!uv pip -q install ultralytics opencv-python matplotlib\n","import ultralytics\n","ultralytics.checks()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQSY8pufUu7X","executionInfo":{"status":"ok","timestamp":1762267712676,"user_tz":-420,"elapsed":4896,"user":{"displayName":"Piramid Surin","userId":"02095017345641733390"}},"outputId":"3c0f3a12-f4ea-4567-8a01-ea77c13dd798"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.225 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","Setup complete âœ… (2 CPUs, 12.7 GB RAM, 39.2/112.6 GB disk)\n"]}]},{"cell_type":"markdown","source":["## Add reusable functions"],"metadata":{"id":"KUwBQ75WVhuO"}},{"cell_type":"code","source":["\"\"\"\n","detect_fish.py\n","\n","Simple, reusable script to detect fish in images and videos using Ultralytics YOLO (v8+).\n","\n","Functions:\n"," - load_model(weights='yolov8n.pt') -> YOLO model\n"," - detect_image(image_path, model, class_name='fish', conf_thres=0.4, save_path=None)\n"," - process_video(video_path, model, class_name='fish', conf_thres=0.4, output_path=None)\n","\n","Notes:\n"," - This script expects `ultralytics` and `opencv-python` installed.\n"," - On Colab: install with `pip install ultralytics opencv-python` (and appropriate torch build).\n","\"\"\"\n","\n","from ultralytics import YOLO\n","import cv2\n","import os\n","import time\n","import numpy as np\n","from typing import Tuple, Optional\n","\n","\n","def load_model(weights: str = 'yolov8n.pt') -> YOLO:\n","    \"\"\"Load a YOLO model (from ultralytics).\n","\n","    Default is `yolov8n.pt` (small, fast). You can switch to `yolov8s.pt`,\n","    `yolov8m.pt`, or a custom weights file.\n","    \"\"\"\n","    model = YOLO(weights)\n","    return model\n","\n","\n","def _draw_box(img: np.ndarray, xyxy: Tuple[int, int, int, int], label: str, conf: float, color=(0,255,0)):\n","    x1, y1, x2, y2 = xyxy\n","    cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n","    text = f\"{label} {conf:.2f}\"\n","    (tw, th), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n","    cv2.rectangle(img, (x1, y1 - 18), (x1 + tw, y1), color, -1)\n","    cv2.putText(img, text, (x1, y1 - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n","\n","\n","def detect_image(image_path: str, model: YOLO, class_name: str = 'fish', conf_thres: float = 0.4, save_path: Optional[str] = None) -> Tuple[np.ndarray, int]:\n","    \"\"\"Detect fish in an image, draw boxes and return annotated image and count.\n","\n","    - image_path: path to input image\n","    - model: loaded YOLO model\n","    - class_name: name of target class to count (e.g., 'fish')\n","    - conf_thres: confidence threshold for filtering detections\n","    - save_path: if provided, save annotated image to this path\n","\n","    Returns (annotated_image, fish_count)\n","    \"\"\"\n","    img = cv2.imread(image_path)\n","    if img is None:\n","        raise FileNotFoundError(f\"Could not read image: {image_path}\")\n","\n","    results = model(img)\n","    res = results[0]\n","\n","    # model.names maps class index -> name\n","    names = model.names if hasattr(model, 'names') else {}\n","\n","    fish_count = 0\n","    if len(res.boxes) > 0:\n","        for box in res.boxes:\n","            # Each box has xyxy, conf, cls as tensors with shape (1,)\n","            try:\n","                xyxy = box.xyxy[0].cpu().numpy().astype(int)\n","                conf = float(box.conf[0].cpu().numpy())\n","                cls_idx = int(box.cls[0].cpu().numpy())\n","            except Exception:\n","                # Fallback if API shapes differ\n","                xyxy = box.xyxy[0].numpy().astype(int)\n","                conf = float(box.conf[0].numpy())\n","                cls_idx = int(box.cls[0].numpy())\n","\n","            label = names.get(cls_idx, str(cls_idx))\n","            if label.lower() == class_name.lower() and conf >= conf_thres:\n","                fish_count += 1\n","                _draw_box(img, tuple(xyxy.tolist()), label, conf, color=(0,200,0))\n","\n","    # overlay count\n","    h, w = img.shape[:2]\n","    info = f\"Fish count: {fish_count}\"\n","    cv2.rectangle(img, (5,5), (200,30), (0,0,0), -1)\n","    cv2.putText(img, info, (10,23), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n","\n","    if save_path:\n","        cv2.imwrite(save_path, img)\n","\n","    return img, fish_count\n","\n","\n","def process_video(video_path: str, model: YOLO, class_name: str = 'fish', conf_thres: float = 0.4, output_path: Optional[str] = None, max_frames: Optional[int] = None):\n","    \"\"\"Process a video frame-by-frame, detect fish, draw boxes and save result video.\n","\n","    - video_path: input video file\n","    - model: loaded YOLO model\n","    - output_path: if None, will create `<video_path>_out.mp4`\n","    - max_frames: optional cap to process only N frames (useful for tests)\n","    \"\"\"\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        raise FileNotFoundError(f\"Could not open video: {video_path}\")\n","\n","    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n","    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","\n","    if output_path is None:\n","        base, ext = os.path.splitext(video_path)\n","        output_path = base + '_out.mp4'\n","\n","    out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))\n","\n","    frame_idx = 0\n","    t_start = time.time()\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        results = model(frame)\n","        res = results[0]\n","\n","        fish_count = 0\n","        if len(res.boxes) > 0:\n","            for box in res.boxes:\n","                try:\n","                    xyxy = box.xyxy[0].cpu().numpy().astype(int)\n","                    conf = float(box.conf[0].cpu().numpy())\n","                    cls_idx = int(box.cls[0].cpu().numpy())\n","                except Exception:\n","                    xyxy = box.xyxy[0].numpy().astype(int)\n","                    conf = float(box.conf[0].numpy())\n","                    cls_idx = int(box.cls[0].numpy())\n","\n","                label = model.names.get(cls_idx, str(cls_idx))\n","                if label.lower() == class_name.lower() and conf >= conf_thres:\n","                    fish_count += 1\n","                    _draw_box(frame, tuple(xyxy.tolist()), label, conf)\n","\n","        cv2.rectangle(frame, (5,5), (220,30), (0,0,0), -1)\n","        cv2.putText(frame, f\"Fish: {fish_count}\", (10,23), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n","\n","        out.write(frame)\n","\n","        frame_idx += 1\n","        if max_frames and frame_idx >= max_frames:\n","            break\n","\n","    cap.release()\n","    out.release()\n","    t_end = time.time()\n","    print(f\"Processed {frame_idx} frames in {t_end - t_start:.1f}s -> saved to {output_path}\")\n","\n","\n","# if __name__ == '__main__':\n","#     # Example quick-run using files in this repo's `test-fish` folder\n","#     here = os.path.dirname(__file__)\n","#     test_dir = os.path.join(here, 'test-fish')\n","#     img_example = os.path.join(test_dir, 'Fish-1.jpg')\n","#     vid_example = os.path.join(test_dir, 'vdo-1.mp4')\n","\n","#     print('Loading model (this may download weights the first time)')\n","#     # default to a lightweight YOLOv8 model; change if you need more accuracy\n","#     model = load_model('yolov8n.pt')\n","\n","#     if os.path.exists(img_example):\n","#         out_img = os.path.join(here, 'test-fish', 'Fish-1_out.jpg')\n","#         _, count = detect_image(img_example, model, class_name='fish', conf_thres=0.4, save_path=out_img)\n","#         print(f'Image done, fish count={count}, saved {out_img}')\n","\n","#     if os.path.exists(vid_example):\n","#         out_vid = os.path.join(here, 'test-fish', 'vdo-1_out.mp4')\n","#         process_video(vid_example, model, class_name='fish', conf_thres=0.4, output_path=out_vid, max_frames=300)\n"],"metadata":{"id":"B4RayD8sU1ye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9z25yO4rVqWL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Start the prediction"],"metadata":{"id":"FqvJ-i3jV8HD"}},{"cell_type":"code","source":["# Run inference on an image with YOLO11n\n","!yolo predict model=yolo11n.pt source='https://ultralytics.com/images/zidane.jpg'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3T26--H-V-TU","executionInfo":{"status":"ok","timestamp":1762267762484,"user_tz":-420,"elapsed":7875,"user":{"displayName":"Piramid Surin","userId":"02095017345641733390"}},"outputId":"a4a85ac6-63e7-4ae7-bb3b-411f3268420c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\r\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 94.6MB/s 0.1s\r\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 94.4MB/s 0.1s\n","Ultralytics 8.3.225 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n","\n","\u001b[KDownloading https://ultralytics.com/images/zidane.jpg to 'zidane.jpg': 100% â”â”â”â”â”â”â”â”â”â”â”â” 49.2KB 6.8MB/s 0.0s\n","image 1/1 /content/zidane.jpg: 384x640 2 persons, 1 tie, 48.4ms\n","Speed: 12.2ms preprocess, 48.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","Results saved to \u001b[1m/content/runs/detect/predict\u001b[0m\n","ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"]}]},{"cell_type":"code","source":["!yolo val model=yolo11n.pt data=coco8.yaml classes=fish"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZkTEVH8lV-9n","executionInfo":{"status":"ok","timestamp":1762267959963,"user_tz":-420,"elapsed":14264,"user":{"displayName":"Piramid Surin","userId":"02095017345641733390"}},"outputId":"40fada63-3c1d-4773-a71e-1f9b15fe6ca8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.225 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n","\n","WARNING âš ï¸ Dataset 'coco8.yaml' images not found, missing path '/content/datasets/coco8/images/val'\n","\u001b[KDownloading https://ultralytics.com/assets/coco8.zip to '/content/datasets/coco8.zip': 100% â”â”â”â”â”â”â”â”â”â”â”â” 432.8KB 17.6MB/s 0.0s\n","\u001b[KUnzipping /content/datasets/coco8.zip to /content/datasets/coco8...: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 3.6Kfiles/s 0.0s\n","Dataset download success âœ… (0.5s), saved to \u001b[1m/content/datasets\u001b[0m\n","\n","\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 24.3MB/s 0.0s\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1773.2Â±630.0 MB/s, size: 54.0 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 117.5it/s 0.0s\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco8/labels/val.cache\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.7it/s 0.2s\n","/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:650: RuntimeWarning: Mean of empty slice.\n","  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n","/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n","  ret = ret.dtype.type(ret / rcount)\n","/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:694: RuntimeWarning: Mean of empty slice.\n","  y = smooth(py.mean(0), 0.1)\n","/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n","  ret = um.true_divide(\n","/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:694: RuntimeWarning: Mean of empty slice.\n","  y = smooth(py.mean(0), 0.1)\n","/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n","  ret = um.true_divide(\n","/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:694: RuntimeWarning: Mean of empty slice.\n","  y = smooth(py.mean(0), 0.1)\n","/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n","  ret = um.true_divide(\n","/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:829: RuntimeWarning: Mean of empty slice.\n","  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n","                   all          4          0          0          0          0          0\n","WARNING âš ï¸ no labels found in detect set, can not compute metrics without labels\n","Speed: 2.8ms preprocess, 32.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n","Results saved to \u001b[1m/content/runs/detect/val\u001b[0m\n","ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"OT2FraQfWtnR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Train"],"metadata":{"id":"5MeG4EmmXddg"}},{"cell_type":"code","source":["#@title Select YOLO11 ğŸš€ logger {run: 'auto'}\n","logger = 'TensorBoard' #@param ['TensorBoard', 'Weights & Biases']\n","\n","if logger == 'TensorBoard':\n","  !yolo settings tensorboard=True\n","  %load_ext tensorboard\n","  %tensorboard --logdir .\n","elif logger == 'Weights & Biases':\n","  !yolo settings wandb=True"],"metadata":{"id":"gSk2TbXSXegy"},"execution_count":null,"outputs":[]}]}